{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archivo general probando keras, viendo qué hace cada capa y cómo tira mejor \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\Juan\\Desktop\\Proyecto_Final_NLP\\phil_nlp.csv\") #archivo etiquetado "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'author', 'school', 'sentence_spacy', 'sentence',\n",
       "       'sentence_length', 'sentence_lowered', 'tokenized_txt',\n",
       "       'lemmatized_str'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>school</th>\n",
       "      <th>sentence_spacy</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>sentence_lowered</th>\n",
       "      <th>tokenized_txt</th>\n",
       "      <th>lemmatized_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Plato - Complete Works</td>\n",
       "      <td>Plato</td>\n",
       "      <td>plato</td>\n",
       "      <td>What's new, Socrates, to make you leave your ...</td>\n",
       "      <td>What's new, Socrates, to make you leave your ...</td>\n",
       "      <td>125</td>\n",
       "      <td>what's new, socrates, to make you leave your ...</td>\n",
       "      <td>['what', 'new', 'socrates', 'to', 'make', 'you...</td>\n",
       "      <td>what be new , Socrates , to make -PRON- lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plato - Complete Works</td>\n",
       "      <td>Plato</td>\n",
       "      <td>plato</td>\n",
       "      <td>Surely you are not prosecuting anyone before t...</td>\n",
       "      <td>Surely you are not prosecuting anyone before t...</td>\n",
       "      <td>69</td>\n",
       "      <td>surely you are not prosecuting anyone before t...</td>\n",
       "      <td>['surely', 'you', 'are', 'not', 'prosecuting',...</td>\n",
       "      <td>surely -PRON- be not prosecute anyone before ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Plato - Complete Works</td>\n",
       "      <td>Plato</td>\n",
       "      <td>plato</td>\n",
       "      <td>The Athenians do not call this a prosecution b...</td>\n",
       "      <td>The Athenians do not call this a prosecution b...</td>\n",
       "      <td>74</td>\n",
       "      <td>the athenians do not call this a prosecution b...</td>\n",
       "      <td>['the', 'athenians', 'do', 'not', 'call', 'thi...</td>\n",
       "      <td>the Athenians do not call this a prosecution ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Plato - Complete Works</td>\n",
       "      <td>Plato</td>\n",
       "      <td>plato</td>\n",
       "      <td>What is this you say?</td>\n",
       "      <td>What is this you say?</td>\n",
       "      <td>21</td>\n",
       "      <td>what is this you say?</td>\n",
       "      <td>['what', 'is', 'this', 'you', 'say']</td>\n",
       "      <td>what be this -PRON- say ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Plato - Complete Works</td>\n",
       "      <td>Plato</td>\n",
       "      <td>plato</td>\n",
       "      <td>Someone must have indicted you, for you are no...</td>\n",
       "      <td>Someone must have indicted you, for you are no...</td>\n",
       "      <td>101</td>\n",
       "      <td>someone must have indicted you, for you are no...</td>\n",
       "      <td>['someone', 'must', 'have', 'indicted', 'you',...</td>\n",
       "      <td>someone must have indict -PRON- , for -PRON- ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    title author school  \\\n",
       "0  Plato - Complete Works  Plato  plato   \n",
       "1  Plato - Complete Works  Plato  plato   \n",
       "2  Plato - Complete Works  Plato  plato   \n",
       "3  Plato - Complete Works  Plato  plato   \n",
       "4  Plato - Complete Works  Plato  plato   \n",
       "\n",
       "                                      sentence_spacy  \\\n",
       "0   What's new, Socrates, to make you leave your ...   \n",
       "1  Surely you are not prosecuting anyone before t...   \n",
       "2  The Athenians do not call this a prosecution b...   \n",
       "3                              What is this you say?   \n",
       "4  Someone must have indicted you, for you are no...   \n",
       "\n",
       "                                            sentence  sentence_length  \\\n",
       "0   What's new, Socrates, to make you leave your ...              125   \n",
       "1  Surely you are not prosecuting anyone before t...               69   \n",
       "2  The Athenians do not call this a prosecution b...               74   \n",
       "3                              What is this you say?               21   \n",
       "4  Someone must have indicted you, for you are no...              101   \n",
       "\n",
       "                                    sentence_lowered  \\\n",
       "0   what's new, socrates, to make you leave your ...   \n",
       "1  surely you are not prosecuting anyone before t...   \n",
       "2  the athenians do not call this a prosecution b...   \n",
       "3                              what is this you say?   \n",
       "4  someone must have indicted you, for you are no...   \n",
       "\n",
       "                                       tokenized_txt  \\\n",
       "0  ['what', 'new', 'socrates', 'to', 'make', 'you...   \n",
       "1  ['surely', 'you', 'are', 'not', 'prosecuting',...   \n",
       "2  ['the', 'athenians', 'do', 'not', 'call', 'thi...   \n",
       "3               ['what', 'is', 'this', 'you', 'say']   \n",
       "4  ['someone', 'must', 'have', 'indicted', 'you',...   \n",
       "\n",
       "                                      lemmatized_str  \n",
       "0     what be new , Socrates , to make -PRON- lea...  \n",
       "1   surely -PRON- be not prosecute anyone before ...  \n",
       "2   the Athenians do not call this a prosecution ...  \n",
       "3                          what be this -PRON- say ?  \n",
       "4   someone must have indict -PRON- , for -PRON- ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"sentence_lowered\"]\n",
    "y = df[\"school\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_sequence_length = max([len(x) for x in X_train_seq])\n",
    "X_train_padded = pad_sequences(X_train_seq, maxlen=max_sequence_length)\n",
    "X_test_padded = pad_sequences(X_test_seq, maxlen=max_sequence_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(max_sequence_length,), activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8104/8104 [==============================] - 16s 2ms/step - loss: 14.4778 - accuracy: 0.1633 - val_loss: 2.2313 - val_accuracy: 0.1639\n",
      "Epoch 2/10\n",
      "8104/8104 [==============================] - 16s 2ms/step - loss: 2.2413 - accuracy: 0.1651 - val_loss: 2.2312 - val_accuracy: 0.1639\n",
      "Epoch 3/10\n",
      "8104/8104 [==============================] - 16s 2ms/step - loss: 2.2326 - accuracy: 0.1651 - val_loss: 2.2312 - val_accuracy: 0.1639\n",
      "Epoch 4/10\n",
      "8104/8104 [==============================] - 17s 2ms/step - loss: 2.2319 - accuracy: 0.1651 - val_loss: 2.2314 - val_accuracy: 0.1639\n",
      "Epoch 5/10\n",
      "8104/8104 [==============================] - 18s 2ms/step - loss: 2.2315 - accuracy: 0.1651 - val_loss: 2.2311 - val_accuracy: 0.1639\n",
      "Epoch 6/10\n",
      "8104/8104 [==============================] - 19s 2ms/step - loss: 2.2308 - accuracy: 0.1651 - val_loss: 2.2311 - val_accuracy: 0.1639\n",
      "Epoch 7/10\n",
      "8104/8104 [==============================] - 19s 2ms/step - loss: 2.2309 - accuracy: 0.1651 - val_loss: 2.2311 - val_accuracy: 0.1639\n",
      "Epoch 8/10\n",
      "8104/8104 [==============================] - 19s 2ms/step - loss: 2.2308 - accuracy: 0.1651 - val_loss: 2.2311 - val_accuracy: 0.1639\n",
      "Epoch 9/10\n",
      "8104/8104 [==============================] - 19s 2ms/step - loss: 2.2325 - accuracy: 0.1651 - val_loss: 2.2312 - val_accuracy: 0.1639\n",
      "Epoch 10/10\n",
      "8104/8104 [==============================] - 19s 2ms/step - loss: 2.2316 - accuracy: 0.1651 - val_loss: 2.2311 - val_accuracy: 0.1639\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f7262402e0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_padded, y_train_encoded, validation_data=(X_test_padded, y_test_encoded), epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026/2026 [==============================] - 4s 2ms/step - loss: 2.2311 - accuracy: 0.1639\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test_padded, y_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 16.39%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8104/8104 [==============================] - 18s 2ms/step - loss: 2.2308 - accuracy: 0.1651 - val_loss: 2.2313 - val_accuracy: 0.1639\n",
      "Epoch 2/10\n",
      "8104/8104 [==============================] - 18s 2ms/step - loss: 2.2309 - accuracy: 0.1651 - val_loss: 2.2311 - val_accuracy: 0.1639\n",
      "Epoch 3/10\n",
      "8104/8104 [==============================] - 19s 2ms/step - loss: 2.2308 - accuracy: 0.1651 - val_loss: 2.2312 - val_accuracy: 0.1639\n",
      "Epoch 4/10\n",
      "8104/8104 [==============================] - 18s 2ms/step - loss: 2.2308 - accuracy: 0.1651 - val_loss: 2.2312 - val_accuracy: 0.1639\n",
      "Epoch 5/10\n",
      "8104/8104 [==============================] - 19s 2ms/step - loss: 2.2308 - accuracy: 0.1651 - val_loss: 2.2312 - val_accuracy: 0.1639\n",
      "Epoch 6/10\n",
      "8104/8104 [==============================] - 19s 2ms/step - loss: 2.2308 - accuracy: 0.1651 - val_loss: 2.2314 - val_accuracy: 0.1639\n",
      "Epoch 7/10\n",
      "8104/8104 [==============================] - 21s 3ms/step - loss: 2.2309 - accuracy: 0.1651 - val_loss: 2.2313 - val_accuracy: 0.1639\n",
      "Epoch 8/10\n",
      "8104/8104 [==============================] - 20s 2ms/step - loss: 2.2321 - accuracy: 0.1651 - val_loss: 2.2312 - val_accuracy: 0.1639\n",
      "Epoch 9/10\n",
      "8104/8104 [==============================] - 19s 2ms/step - loss: 2.2310 - accuracy: 0.1651 - val_loss: 2.2313 - val_accuracy: 0.1639\n",
      "Epoch 10/10\n",
      "8104/8104 [==============================] - 21s 3ms/step - loss: 2.2309 - accuracy: 0.1651 - val_loss: 2.2313 - val_accuracy: 0.1639\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f726526b50>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train_padded, y_train_encoded, validation_data=(X_test_padded, y_test_encoded), epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"sentence_lowered\"]\n",
    "y = df[\"school\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size = 0.2, random_state = 42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "num_classes = len(label_encoder.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['analytic', 'aristotle', 'capitalism', 'communism', 'continental',\n",
       "       'empiricism', 'german_idealism', 'phenomenology', 'plato',\n",
       "       'rationalism'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = 300  # Maximum sequence length for padding\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_padded = pad_sequences(X_train_seq, maxlen=max_sequence_length)\n",
    "X_test_padded = pad_sequences(X_test_seq, maxlen=max_sequence_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_sequence_length))\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8104/8104 [==============================] - 1450s 179ms/step - loss: 0.8253 - accuracy: 0.7311 - val_loss: 0.6782 - val_accuracy: 0.7774\n",
      "Epoch 2/10\n",
      "8104/8104 [==============================] - 1451s 179ms/step - loss: 0.5405 - accuracy: 0.8248 - val_loss: 0.6494 - val_accuracy: 0.7889\n",
      "Epoch 3/10\n",
      "8104/8104 [==============================] - 1456s 180ms/step - loss: 0.3930 - accuracy: 0.8722 - val_loss: 0.6943 - val_accuracy: 0.7906\n",
      "Epoch 4/10\n",
      "8104/8104 [==============================] - 1458s 180ms/step - loss: 0.2940 - accuracy: 0.9035 - val_loss: 0.7456 - val_accuracy: 0.7913\n",
      "Epoch 5/10\n",
      "8104/8104 [==============================] - 1462s 180ms/step - loss: 0.2255 - accuracy: 0.9260 - val_loss: 0.8632 - val_accuracy: 0.7815\n",
      "Epoch 6/10\n",
      "8104/8104 [==============================] - 1465s 181ms/step - loss: 0.1793 - accuracy: 0.9405 - val_loss: 0.9531 - val_accuracy: 0.7774\n",
      "Epoch 7/10\n",
      "8104/8104 [==============================] - 1461s 180ms/step - loss: 0.1490 - accuracy: 0.9505 - val_loss: 1.0251 - val_accuracy: 0.7758\n",
      "Epoch 8/10\n",
      "8104/8104 [==============================] - 1460s 180ms/step - loss: 0.1279 - accuracy: 0.9572 - val_loss: 1.1921 - val_accuracy: 0.7728\n",
      "Epoch 9/10\n",
      "8104/8104 [==============================] - 1459s 180ms/step - loss: 0.1112 - accuracy: 0.9630 - val_loss: 1.2361 - val_accuracy: 0.7736\n",
      "Epoch 10/10\n",
      "8104/8104 [==============================] - 1460s 180ms/step - loss: 0.0987 - accuracy: 0.9667 - val_loss: 1.3857 - val_accuracy: 0.7710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23423bc28e0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_padded, y_train_encoded, validation_data=(X_test_padded, y_test_encoded), epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026/2026 [==============================] - 14s 7ms/step - loss: 1.3857 - accuracy: 0.7710\n",
      "Accuracy: 77.10%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test_padded, y_test_encoded)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open('modelkerasnlp.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
